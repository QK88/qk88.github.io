---
layout:     post
title:      Content-based image retrieval
subtitle:   
date:       2020-05-12
author:     QK
catalog: true
tags:
    - Sift
    - Kmeans
    - unsupervised learning
    - matlab

---

<!-- MarkdownTOC -->

### outline

​	图像检索系统的实现有两种实现方式：基于文本的图像检索，基于内容的图像检索，这里采用的人工智能无监督学习经典算法KMeans算法实现基于内容的方式构建图像检索系统。





### Sift

​	说明：SIFT算法的实质是在不同的尺度空间上查找关键点(特征点)，并计算出关键点的方向。SIFT所查找到的关键点是一些十分突出，不会因光照，仿射变换和噪音等因素而变化的点，如角点、边缘点、暗区的亮点及亮区的暗点等

#### 构建高斯差分DOG金字塔

​	高斯核是唯一可以产生多尺度空间的核一个图像的尺度空间L(x,y,σ) ,定义为原始图像I(x,y)与一个可变尺度的2维高斯函数G(x,y,σ)卷积运算。

​	高斯差分空间利用不同尺度的高斯差分核与图像卷积生成，图像的金字塔模型是指，将原始图像不断降阶采样，得到一系列大小不一的图像，由大到小，从下到上构成的塔状模型。

<div align="center">
<img src="../img\img-content-based image retrieval\高斯金字塔.png" alt="高斯金字塔" style="zoom:50%;"  />
</div>
<center>图1：高斯金字塔模型</center>

​	说明：高斯金字塔上一组图像的初始图像(底层图像)是由前一组图像的倒数第三张图像隔点采样得到的。相邻两组的同一层尺度为2倍的关系。因此得到高斯差分金字塔首先需要构建高斯金字塔。因为高斯金字塔由层间差分而来因此每组至少组数加一，因为为下一步需要差分来求解求极值点，因此构建的高斯金字塔模型需要比目标DOG组数加2.

<div align="center">
<img src="../img\img-content-based image retrieval\金字塔组间关系.png" alt="金字塔组间关系" style="zoom:50%"/>
</div>

<center>图2：高斯金字塔组间关系</center>

代码说明：

```matlab
do_gaussian(I,sigmaN,O,S,omin,smin,smax,sigma0);%此函数为构建高斯金字塔

do_diffofg(scalespace);%此函数为构建高斯差分金字塔
```



#### 空间极值检测

​	关键点是由DOG空间的局部极值点组成的，关键点的初步探查是通过同一组内各DOG相邻两层图像之间比较完成的。为了寻找DOG函数的极值点，每一个像素点要和它所有的相邻点比较，看其是否比它的图像域和尺度域的相邻点大或者小

缺点：极值点并不全都是稳定的特征点，因为某些极值点响应较弱，而且DOG算子会产生较强的边缘响应

<img src="../img\img-content-based image retrieval\空间极值检测.png" style="zoom:50%;" />

#### 关键点定位

​	以上方法检测到的极值点是离散空间的极值点，以下通过拟合三维二次函数来精确确定关键点的位置和尺度，同时去除低对比度的关键点和不稳定的边缘响应点(因为DOG算子会产生较强的边缘响应)，以增强匹配稳定性、提高抗噪声能力

<img src="../img\img-content-based image retrieval\极值点拟合.png" style="zoom:75%;" />

#### 关键点方向分配

​	为了使描述符具有旋转不变性，需要利用图像的局部特征为给每一个关键点分配一个基准方向。使用图像梯度的方法求取局部结构的稳定方向。

<img src="C:\Code\Blog\qk88.github.io\img\img-content-based image retrieval\旋转不变性.png" style="zoom:75%;" />

​	在完成关键点的梯度计算后，使用直方图统计邻域内像素的梯度和方向。梯度直方图将0~360度的方向范围分为若干个柱(bins)，其中每柱10度。直方图的峰值方向代表了关键点的主方向

<img src="C:\Code\Blog\qk88.github.io\img\img-content-based image retrieval\向量分配.png" style="zoom:75%;" />

​	方向直方图的峰值则代表了该特征点处邻域梯度的方向，以直方图中最大值作为该关键点的主方向。为了增强匹配的鲁棒性，只保留峰值大于主方向峰值80％的方向作为该关键点的辅方向。因此，对于同一梯度值的多个峰值的关键点位置，在相同位置和尺度将会有多个关键点被创建但方向不同。仅有15％的关键点被赋予多个方向，但可以明显的提高关键点匹配的稳定性。实际编程实现中，就是把该关键点复制成多份关键点，并将方向值分别赋给这些复制后的关键点

#### 关键点描述

SIFT描述子是关键点邻域高斯图像梯度统计结果的一种表示。通过对关键点周围图像区域分块，计算块内梯度直方图，生成具有独特性的向量，这个向量是该区域图像信息的一种抽象，具有唯一性。

通过以下步骤实现对于特征点区域的描述

1. 确定计算描述子所需的图像区域

2. 将坐标轴旋转为关键点的方向，以确保旋转不变性

3. 将邻域内的采样点分配到对应的子区域内，将子区域内的梯度值分配到8个方向上，计算其权值。旋转后的采样点坐标在半径为radius的圆内被分配到的子区域，计算影响子区域的采样点的梯度和方向，分配到8个方向上。


4. 插值计算每个种子点八个方向的梯度，得到128维特征描述向量

### KMeans聚类算法

​	对于"监督学习"(supervised learning)，其训练样本是带有标记信息的，并且监督学习的目的是：对带有标记的数据集进行模型学习，从而便于对新的样本进行分类。而在“无监督学习”(unsupervised learning)中，训练样本的标记信息是未知的，目标是通过对无标记训练样本的学习来揭示数据的内在性质及规律，为进一步的数据分析提供基础。对于无监督学习，应用最广的便是"聚类"(clustering)。

​	“聚类算法”试图将数据集中的样本划分为若干个通常是不相交的子集，每个子集称为一个“簇”(cluster)，通过这样的划分，每个簇可能对应于一些潜在的概念或类别。

​	kmeans算法又名k均值算法。其算法思想大致为：先从样本集中随机选取 k 个样本作为簇中心，并计算所有样本与这 k 个“簇中心”的距离，对于每一个样本，将其划分到与其距离最近的“簇中心”所在的簇中，对于新的簇计算各个簇的新的“簇中心”。

根据以上描述，我们大致可以猜测到实现kmeans算法的主要三点：

（1）簇个数 k 的选择

（2）各个样本点到“簇中心”的距离

（3）根据新划分的簇，更新“簇中心”



输入：训练数据集 $D ={x{(1)},x{(2)},...,x^{(m)}},聚类簇数,聚类簇数 k$ ;
  过程：函数 kMeans(D,k,maxIter)kMeans(D,k,maxIter) .
  1：从 DD 中随机选择 kk 个样本作为初始“簇中心”向量： $ {\mu{(1)},\mu{(2)},...,,\mu^{(k)}} $ :
  2：repeat
  3：  令 Ci=∅(1≤i≤k)Ci=∅(1≤i≤k)
  4：  for j=1,2,...,mj=1,2,...,m do
  5：    计算样本 x(j)x(j) 与各“簇中心”向量 μ(i)(1≤i≤k)μ(i)(1≤i≤k) 的欧式距离
  6：    根据距离最近的“簇中心”向量确定 x(j)x(j) 的簇标记： λj=argmini∈{1,2,...,k}djiλj=argmini∈{1,2,...,k}dji
  7：    将样本 x(j)x(j) 划入相应的簇： Cλj=Cλj⋃{x(j)}Cλj=Cλj⋃{x(j)} ;
  8：  end for
  9：  for i=1,2,...,ki=1,2,...,k do
  10：    计算新“簇中心”向量： (μ(i))′=1|Ci|∑x∈Cix(μ(i))′=1|Ci|∑x∈Cix ;
  11：    if (μ(i))′=μ(i)(μ(i))′=μ(i) then
  12：      将当前“簇中心”向量 μ(i)μ(i) 更新为 (μ(i))′(μ(i))′
  13：    else
  14：      保持当前均值向量不变
  15：    end if
  16：  end for
  17：  else
  18：until 当前“簇中心”向量均未更新


#### 根据聚类特征分析匹配度

​	余弦相似度用向量空间中两个向量夹角的余弦值作为衡量两个个体间差异的大小。余弦值越接近1，就表明夹角越接近0度，也就是两个向量越相似，这就叫”余弦相似性”，因此利用余弦定理的特性可以利用余弦定理判断feats特征点相似性，由于kmeans聚类算法将128维向量转化为k类，然后计算目标图像与原图像相似性